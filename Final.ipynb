{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (743981363.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [2]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install seaborn\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "df = pd.read_csv ('data.csv')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "def depth_plot(ax,df,feat,postfix):\n",
    "    ax.plot(df[feat],df['Depth'],'b.')\n",
    "    ax.set_xlim(min(df[feat]),max(df[feat]))\n",
    "    ax.set_ylim(2800,4200)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Depth')\n",
    "    #ax.figure.set_size_inches(ax.figure.get_size_inches()[1]/2, ax.figure.get_size_inches()[1])\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig('depth_'+postfix+'.png')\n",
    "def freq_plot(ax,df,feat,postfix):\n",
    "    ax.hist(df[feat],color = \"blue\")\n",
    "    ax.set_xlabel(feat)\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig('hist_'+postfix+'.png')\n",
    "    \n",
    "    \n",
    "feats=['DT','NPHI','RHOB','PEF','RT','SGR']\n",
    "\n",
    "fig, axis = plt.subplots(2,3)\n",
    "for i,feat in enumerate(feats):  \n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    freq_plot(ax,df,feat,'before') \n",
    "#plt.show()\n",
    "#plt.cla()\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(2,3)\n",
    "for i,feat in enumerate(feats):  \n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    depth_plot(ax,df,feat,'before')#,label,xlabel )  \n",
    "#plt.show()\n",
    "#plt.cla()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers\n",
    "'''\n",
    "instruction to remove the entire rows when they have outlier and/or null values. Note that if any of these conditions are satisfied, the entire row will be deleted.\n",
    "DT smaller than 0 || DT greater than 100\n",
    "NPHI smaller than -0.1 || NPHI greater than 0.45\n",
    "RHOB smaller than 2.0 || RHOB greater than 3.0\n",
    "PEF smaller than 0.0 || PEF greater than 7.0\n",
    "RT smaller than 0.0 || RT greater than 2000\n",
    "GR smaller than 0 || GR greater than150\n",
    "'''\n",
    "df = df.dropna(axis=1)\n",
    "df = df.drop(df[(df['DT'] < 0.0) | (df['DT'] >100.0)].index)\n",
    "df = df.drop(df[(df['NPHI'] < -0.1) | (df['NPHI'] >0.45)].index)\n",
    "df = df.drop(df[(df['RHOB'] < 2.0) | (df['RHOB'] >3.0)].index)\n",
    "df = df.drop(df[(df['PEF'] < 0.0) | (df['PEF'] >7.0)].index)\n",
    "df = df.drop(df[(df['RT'] < 0.0) | (df['RT'] >2000)].index)\n",
    "df = df.drop(df[(df['SGR'] < 0.0) | (df['SGR'] >150.0)].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axis = plt.subplots(2,3)\n",
    "for i,feat in enumerate(feats): \n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    freq_plot(ax,df,feat,'after') \n",
    "#plt.show()\n",
    "#plt.cla()\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(2,3)\n",
    "for i,feat in enumerate(feats):  \n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    depth_plot(ax,df,feat,'after')#,label,xlabel ) \n",
    "#plt.show()\n",
    "#plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scale data between 0-1\n",
    "new_data = preprocessing.MinMaxScaler().fit_transform(df[feats])\n",
    "df_new=pd.DataFrame(new_data, columns = feats)\n",
    "df_new.insert(loc=0, column='Depth', value=df['Depth'])\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(2,3)\n",
    "for i,feat in enumerate(feats):  \n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    depth_plot(ax,df_new,feat,'_scaled')#,label,xlabel )  \n",
    "#plt.show()\n",
    "#plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########scatter plots##############\n",
    "def scatter_plot(df,feat1,feat2,col,i):\n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    ax.scatter(df[feat1],df[feat2],s=1,c=df[col],cmap='hot')\n",
    "    ax.set_xlabel(feat1, fontsize=15)\n",
    "    ax.set_ylabel(feat2, fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig('colored_by_'+col+'.png')\n",
    "\n",
    "i=0\n",
    "fig, axis = plt.subplots(2,3)\n",
    "scatter_plot(df_new,'PEF','SGR',feat,0)  \n",
    "scatter_plot(df_new,'SGR','RT',feat,1)\n",
    "scatter_plot(df_new,'PEF','RHOB',feat,2)\n",
    "scatter_plot(df_new,'PEF','DT',feat,3)\n",
    "scatter_plot(df_new,'DT','RHOB',feat,4)\n",
    "scatter_plot(df_new,'NPHI','RHOB',feat,5)\n",
    "\n",
    "#plt.show()\n",
    "#plt.cla()\n",
    "\n",
    "#scatter_plot(df_new,'NPHI','DT',feat,i++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########Density plots##############\n",
    "\n",
    "def freq_plot(df,feat1,feat2,i):\n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    sns.set_palette(\"Reds\")\n",
    "    res = sns.kdeplot(df_new[feat1],df_new[feat2],shade=True,ax=ax)\n",
    "    res.set(xlabel=feat1, ylabel=feat2)\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig('colored_by_freq.png')\n",
    "    i+=1\n",
    "    #plt.show()\n",
    "#plt.cla()\n",
    "fig, axis = plt.subplots(2,3)\n",
    "i=0   \n",
    "freq_plot(df_new,'PEF','SGR',i); i+=1\n",
    "freq_plot(df_new,'PEF','RHOB',i); i+=1\n",
    "freq_plot(df_new,'PEF','DT',i); i+=1\n",
    "freq_plot(df_new,'DT','RHOB',i); i+=1\n",
    "freq_plot(df_new,'NPHI','RHOB',i); i+=1\n",
    "freq_plot(df_new,'NPHI','DT',i); i+=1\n",
    "#plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,SpectralClustering,AgglomerativeClustering,DBSCAN\n",
    "from sklearn.mixture import GaussianMixture,BayesianGaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "db_score=100\n",
    "best_algo='None'\n",
    "db_arr=[]\n",
    "labels=[]\n",
    "\n",
    "def scatter_plot_cluster(df,feat1,feat2,col,clus_name,i):\n",
    "    ax=axis[math.floor(i/3), math.floor(i%3)]\n",
    "    ax.scatter(df[feat1],df[feat2],s=1,c=col,cmap='jet')\n",
    "    ax.set_xlabel(feat1, fontsize=15)\n",
    "    ax.set_ylabel(feat2, fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig(clus_name+'.png')\n",
    "\n",
    "cls_algos = ['KMeans','SpectralClustering','AgglomerativeClustering','DBSCAN']\n",
    "for algo in cls_algos:\n",
    "    if algo=='DBSCAN':\n",
    "        cls=DBSCAN(eps=0.05)\n",
    "    else:\n",
    "        cls=globals()[algo](n_clusters=4) \n",
    "    col = cls.fit_predict(df_new[feats])\n",
    "    db_new=davies_bouldin_score(df_new[feats],col)\n",
    "    db_arr.append(db_new)\n",
    "    if db_new<db_score:\n",
    "        best_algo=algo\n",
    "        db_score=db_new\n",
    "        labels=col\n",
    "    cl_name=algo\n",
    "    fig, axis = plt.subplots(2,3)\n",
    "    i=0   \n",
    "    scatter_plot_cluster(df_new,'PEF','SGR',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'PEF','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'PEF','DT',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'DT','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'NPHI','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'SGR','RT',col,cl_name,i); i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls_algos = ['GaussianMixture','BayesianGaussianMixture']\n",
    "for algo in cls_algos:\n",
    "    cls = GaussianMixture(n_components=4)\n",
    "    col = cls.fit_predict(df_new[feats])\n",
    "    cl_name=algo\n",
    "    db_new=davies_bouldin_score(df_new[feats],col)\n",
    "    db_arr.append(db_new)\n",
    "    if db_new<db_score:\n",
    "        best_algo=algo\n",
    "        db_score=db_new\n",
    "        labels=col\n",
    "    fig, axis = plt.subplots(2,3)\n",
    "    i=0   \n",
    "    scatter_plot_cluster(df_new,'PEF','SGR',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'PEF','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'PEF','DT',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'DT','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'NPHI','RHOB',col,cl_name,i); i+=1\n",
    "    scatter_plot_cluster(df_new,'SGR','RT',col,cl_name,i); i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db_arr)\n",
    "print(\"best algo is \",best_algo,\"with score \",db_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['label']=labels\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def plot_regression(y_test,y_pred,title,cls_id,i):\n",
    "    ax=axis[i]\n",
    "    ax.scatter(y_test,y_pred,color=\"black\")\n",
    "    z = np.polyfit(y_test,y_pred, 1)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    #add trendline to plot\n",
    "    ax.plot(y_test, p(y_test),color=\"blue\", linewidth=3)\n",
    "    #plt.plot(np.array(X)[ind_test,:],y_pred, color=\"blue\", linewidth=3)\n",
    "    ax.set_title(title,fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    ax.figure.savefig('Regression_cluster'+str(cls_id)+'.png')\n",
    "#select a cluster\n",
    "cluster=df_new[df_new['label']==1].reset_index()\n",
    "X=cluster[['DT', 'RHOB', 'SGR', 'NPHI']]\n",
    "y=cluster['PEF']\n",
    "mseArr=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "PF = PolynomialFeatures(degree=3, include_bias=True)\n",
    "pFeats=PF.fit_transform(X)\n",
    "pFeats_y=PF.fit_transform(np.array(y).reshape(-1,1))\n",
    "X_train, X_test, y_train, y_test,ind_train,ind_test = train_test_split(pFeats, pFeats_y,np.array(range(0,len(y))), test_size=0.33, random_state=42)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred=reg.predict(X_test)\n",
    "mseArr.append(MSE(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor\n",
    "from pyGRNN import GRNN\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "def apply_regression(reg_mod,X_train, y_train,X_test):\n",
    "    if reg_mod=='linear':\n",
    "        reg = LinearRegression()\n",
    "    elif reg_mod=='lasso':\n",
    "        reg = Lasso(alpha=0.0005)\n",
    "    elif reg_mod=='knn':\n",
    "        reg = KNeighborsRegressor(n_neighbors=3)\n",
    "    elif reg_mod=='DT':\n",
    "        reg = regressor = DecisionTreeRegressor(random_state=42)\n",
    "    elif reg_mod=='GB':\n",
    "        reg = GradientBoostingRegressor(random_state=42)\n",
    "    elif reg_mod=='RF':\n",
    "        reg = RandomForestRegressor(random_state=42)\n",
    "    elif reg_mod=='ADR':\n",
    "        reg = AdaBoostRegressor(random_state=42)\n",
    "    elif reg_mod=='ET':\n",
    "        reg = ExtraTreesRegressor(random_state=42)\n",
    "    elif reg_mod=='GRNN':    \n",
    "        reg = GRNN(calibration = 'gradient_search')\n",
    "    elif reg_mod=='ANN':    \n",
    "        reg = MLPRegressor(random_state=42)\n",
    "    print(reg)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred=reg.predict(X_test) \n",
    "    return y_pred\n",
    "regressions=['poly','linear','lasso','knn','DT','GB','RF','ADR','ET','GRNN','ANN']\n",
    "X_train, X_test, y_train, y_test,ind_train,ind_test = train_test_split(X, y,np.array(range(0,len(y))), test_size=0.33, random_state=42)\n",
    "reg=None\n",
    "for reg_mod in regressions:\n",
    "    reg=None\n",
    "    if reg_mod=='poly':\n",
    "        continue\n",
    "    else:\n",
    "        print(reg_mod)\n",
    "        y_pred=apply_regression(reg_mod,X_train, y_train,X_test)\n",
    "        mseArr.append(MSE(y_test, y_pred))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseArr=np.array(mseArr)\n",
    "best_ind=mseArr.argsort()[:4]\n",
    "print(mseArr)\n",
    "print(best_ind)\n",
    "best_algos=[regressions[i] for i in best_ind if i>0 ]\n",
    "print(best_algos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,4):\n",
    "    fig, axis = plt.subplots(len(best_algos))\n",
    "    ii=0\n",
    "    cluster=df_new[df_new['label']==c].reset_index()\n",
    "    X=cluster[['DT', 'RHOB', 'SGR', 'NPHI']]\n",
    "    y=cluster['PEF']\n",
    "    X_train, X_test, y_train, y_test,ind_train,ind_test = train_test_split(X, y,np.array(range(0,len(y))), test_size=0.33, random_state=42)\n",
    "    for reg_mod in best_algos:\n",
    "        print(reg_mod)\n",
    "        y_pred=apply_regression(reg_mod,X_train, y_train,X_test)\n",
    "        #mseArr.append(MSE(y_test, y_pred))\n",
    "        plot_regression(y_test,y_pred,reg_mod,c,ii);ii+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
